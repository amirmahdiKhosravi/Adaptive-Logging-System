{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458f3c21",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6857dbc7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting javalang\n",
      "  Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: six in /home/amirmahdi/anaconda3/envs/RL_Project2/lib/python3.7/site-packages (from javalang) (1.16.0)\n",
      "Installing collected packages: javalang\n",
      "Successfully installed javalang-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d6a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import ast       #Library to produce AST and analyze it\n",
    "import astor     #Library to produce the actual code of an AST\n",
    "import pandas as pd\n",
    "#import javalang\n",
    "#from javalang.tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b41fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_dict = {}\n",
    "filesname = []\n",
    "file_directories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c4ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this part we make a list of the files' name and their own directory in the given directory.\n",
    "A dictionary is also produced having a hash value of the files name as the key and their actual name as the value.\n",
    "\"\"\"\n",
    "\n",
    "directory = \"/home/amirmahdi/projects/Adaptive-Logging-system-git/projects-to-investigate/allura-master/selected-files-to-investigate\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        filesname.append(filename)\n",
    "        file_directories.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf69358",
   "metadata": {},
   "source": [
    "# Extracting function blocks from source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c22b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function accepts the source code as a string. It first parse it to AST, then iterate through AST and selects \n",
    "nodes that are representing function definition (FunctionDef)\n",
    "\"\"\"\n",
    "\n",
    "def extract_functions(source_code):\n",
    "    tree = ast.parse(source_code)\n",
    "    functions = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            functions.append(node)\n",
    "    return functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd58c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the func_of_files list which each of its elements it is a list of function nodes of a file in the\n",
    "directory.\n",
    "These nodes (subtree of the AST) could be used to creat the actual functions in string by using following code:\n",
    "\n",
    "source_code = astor.to_source(node)\n",
    "\n",
    "Also, in this part, an ID is assigned to each function (based on its name) by using hashlib, then this ID is used as \n",
    "the key value of the \"hash_dict\" which holds a list containing function's name, its directory and list of\n",
    "neighbour functions as the dictionary's value.\n",
    "\"\"\"\n",
    "\n",
    "func_nodes_of_files = []\n",
    "for file_dir in file_directories:\n",
    "    with open(file_dir, \"r\") as file:\n",
    "        source_code = file.read()\n",
    "    functions = extract_functions(source_code)\n",
    "    for function in functions:\n",
    "        functions_copy = functions.copy() # Make a copy of list of functions found in current file\n",
    "        functions_copy.remove(function)    #creating a list of neighbours of current function (in itteratin) by removing itself from functions_copy\n",
    "        hash_dict[ hashlib.sha1(str.encode(function.name)).hexdigest() ] = [file_dir.split(\"/\")[-1], file_dir, \n",
    "                                                                           functions_copy] \n",
    "    func_nodes_of_files.extend(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2678027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dummy_oauths'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_nodes_of_files[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f173c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def dummy_oauths():\n",
      "    from allura.controllers.rest import Oauth1Validator\n",
      "    dummy_cons_tok = OAuthConsumerToken(api_key=Oauth1Validator().\n",
      "        dummy_client, name='dummy client, for oauthlib implementation',\n",
      "        user_id=None)\n",
      "    session(dummy_cons_tok).flush(dummy_cons_tok)\n",
      "    dummy_req_tok = OAuthRequestToken(api_key=Oauth1Validator().\n",
      "        dummy_request_token, user_id=None, validation_pin='dummy-pin')\n",
      "    session(dummy_req_tok).flush(dummy_req_tok)\n",
      "    dummy_access_tok = OAuthAccessToken(api_key=Oauth1Validator().\n",
      "        dummy_access_token, user_id=None)\n",
      "    session(dummy_access_tok).flush(dummy_access_tok)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = astor.to_source(func_nodes_of_files[0])\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffca4d",
   "metadata": {},
   "source": [
    "# Structring Dataset by extracting functions' features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe99ea",
   "metadata": {},
   "source": [
    "## 1. Input-dependent loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e2992",
   "metadata": {},
   "source": [
    "* #### Defining needed functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20a1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_finder(function_node):\n",
    "    loops = []\n",
    "    for node in ast.walk(function_node):\n",
    "        if isinstance(node, ast.For) or isinstance(node, ast.While):\n",
    "            loops.append(node)\n",
    "    return loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484af54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes a source code as input and finds the name of all variables which hold the result of \n",
    "a function call\"\"\"\n",
    "\n",
    "def dependent_variable_finder(source_code):\n",
    "    tree = ast.parse(source_code)             # creating source code's AST\n",
    "    d_variable_names = []\n",
    "    # here it funds variable holding function calls' result\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign):\n",
    "            for node_child in ast.walk(node):\n",
    "                if isinstance(node_child, ast.Call):\n",
    "                    # Parse back the variable assignment node to source code and extract variable names\n",
    "                    d_variable_names.extend(astor.to_source(node).split(\"=\")[0].split(\",\")) \n",
    "                    \n",
    "    return d_variable_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687fc04",
   "metadata": {},
   "source": [
    "* #### Creating Dataframe,then adding \"ID\" and \"number_of_loops\" of a fuction to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e162759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['ID', 'number_of_loops'])\n",
    "#tmp =0\n",
    "for function_node in func_nodes_of_files:\n",
    "    found_loops = loop_finder(function_node)\n",
    "    #tmp += len(found_loops)\n",
    "    ID = hashlib.sha1(str.encode(function_node.name)).hexdigest()\n",
    "    number_of_loops = len(found_loops)\n",
    "    \n",
    "    new_row = pd.Series({\"ID\":ID, \"number_of_loops\":number_of_loops})\n",
    "    df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "df = df.set_index(\"ID\")\n",
    "#df\n",
    "#print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9f829",
   "metadata": {},
   "source": [
    "* #### Adding \"loop_input_dependent_level\" to the dataframe:\n",
    "    \n",
    "    For all of the functions, first we extract all loops inside it (if there is any) by \"using loop_finder\" function. Then we creat a list of kewords representing input_dependent variables and neighbor functions. Doing these two steps, we then search for the keywords in loops' declaration part, and we increment the \"input_dependent_level\" of the given function if any keyword found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e797617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is a recursive function to find a nesting level of a given node representing a loop\"\"\"\n",
    "\n",
    "def nested_loop_level_finder(loop_node):\n",
    "    #nodes_list = ast.walk(loop_node)\n",
    "    nodes_list = ast.iter_child_nodes(loop_node) # this returns a generator\n",
    "    for child_node in nodes_list: # iterate over nodes_list which is a generator.\n",
    "        if isinstance(child_node, ast.For) or isinstance(child_node, ast.While):\n",
    "            return 1 + nested_loop_level_finder(child_node)\n",
    "        elif child_node is not next(nodes_list, None): #checks if it is last item of the generator \n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ed681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This part is to test the nested_loop_level_finder function we defined above\"\"\"\n",
    "\n",
    "s = \"for loop in found_loops:\\n for keyword in keywords:\\n      if keyword in astor.to_source(loop):\\n       input_dependent_level += 1\"\n",
    "tree = ast.parse(s)\n",
    "nested_loop_level_finder(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8b2a9e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this loops iterates over all of the extracted functions to find the input_dependent_level and nested_loop_level\n",
    "for function_node in func_nodes_of_files:\n",
    "    input_dependent_level = 0\n",
    "    nested_loop_level = 0\n",
    "    found_loops = loop_finder(function_node) # here we first find loops.\n",
    "    if len(found_loops) != 0: #if any loop was found\n",
    "        ID = hashlib.sha1(str.encode(function_node.name)).hexdigest()\n",
    "        # use \"has_dict\" to get the neighbour functions of the curent function by using its ID (key):\n",
    "        neighbour_functions_names = [n_function.name for n_function in hash_dict[ID][2]]\n",
    "        \n",
    "        with open(hash_dict[ID][1], \"r\") as file: # hash_dict[ID][1] gives the directory of current function's file\n",
    "            source_code = file.read()\n",
    "        dependent_variable_names = dependent_variable_finder(source_code)\n",
    "        \n",
    "        keywords = dependent_variable_names + neighbour_functions_names\n",
    "        for loop in found_loops: # \"loop\" here is a node of a loop.\n",
    "            for keyword in keywords:\n",
    "                if keyword in astor.to_source(loop).split(\"\\n\")[0]:\n",
    "                    input_dependent_level += 1\n",
    "            \n",
    "            nested_loop_level += nested_loop_level_finder(loop)\n",
    "                \n",
    "    df.at[ID, \"nested_loop_level\"] = int(nested_loop_level)\n",
    "    df.at[ID, \"loop_input_dependent_level\"] = int(input_dependent_level)\n",
    "# the functions without any loops inside will have Nan value for \"loop_input_dependent_level\", so we replace them:\n",
    "df[\"loop_input_dependent_level\"] = df[\"loop_input_dependent_level\"].fillna(0)\n",
    "df[\"nested_loop_level\"] = df[\"loop_input_dependent_level\"].fillna(0) \n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b042c7f",
   "metadata": {},
   "source": [
    "* #### Final version of the dataset having all features related to loops:\n",
    "    The dataset so far includes folowing features:\n",
    "    * **number_of_loops**: \n",
    "        It represents the number of loops (either for or while) inside each of the functions.\n",
    "    * **nested_loop_level**: For the functions which have loop inside them, we check if those loop are nested or not; If a nested loop was found, we increse the nested_loop_level by 1. For example, if a function has the nesting level of 2, it means that this function either has a nested loop with depth of 2, or two nested loops with depth of 1.\n",
    "    * **loop_input_dependent_level**: For this feature, we first creat a list of keywords which includes name of other functions (neighbor functions) and\\or name of dependent variables (variables holding the return value of a function). Then for the functions which has loop(s), we check if any of these keywords has been used in the loop's declaration part or not. Each keyword match will cause an increment of 1 for loop_input_dependent_level.\n",
    "    \n",
    "  Next table shows the dataset so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0651cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_loops</th>\n",
       "      <th>nested_loop_level</th>\n",
       "      <th>loop_input_dependent_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee2c971f20132061d7e749267b166730ff734a7c</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4f01649de54f7e70c368da6571ac5ccda9ddf79</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bae8ac45f183613712be11aee11ec93b6e36e0d0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9aa1369d290e7732b7ca8db743f27d10c0ace093</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9aa1369d290e7732b7ca8db743f27d10c0ace093</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553a4f2a833f635e06b21120fd95dbd7dc3fe09</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05bb76f1e435db71754a65f9e8acec7dfdd4c65d</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4fb170389e1b482ed3c7fae2967caca7629c84a6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ea00c9c71a474f84e3280537f04ede09ae70e44f</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd5e6143d36ce5ffa6caff953de41436984b7fc3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         number_of_loops  nested_loop_level  \\\n",
       "ID                                                                            \n",
       "ee2c971f20132061d7e749267b166730ff734a7c               0                0.0   \n",
       "d4f01649de54f7e70c368da6571ac5ccda9ddf79               0                0.0   \n",
       "bae8ac45f183613712be11aee11ec93b6e36e0d0               0                0.0   \n",
       "9aa1369d290e7732b7ca8db743f27d10c0ace093               0                0.0   \n",
       "9aa1369d290e7732b7ca8db743f27d10c0ace093               0                0.0   \n",
       "...                                                  ...                ...   \n",
       "4553a4f2a833f635e06b21120fd95dbd7dc3fe09               0                0.0   \n",
       "05bb76f1e435db71754a65f9e8acec7dfdd4c65d               0                0.0   \n",
       "4fb170389e1b482ed3c7fae2967caca7629c84a6               0                0.0   \n",
       "ea00c9c71a474f84e3280537f04ede09ae70e44f               0                0.0   \n",
       "fd5e6143d36ce5ffa6caff953de41436984b7fc3               0                0.0   \n",
       "\n",
       "                                          loop_input_dependent_level  \n",
       "ID                                                                    \n",
       "ee2c971f20132061d7e749267b166730ff734a7c                         0.0  \n",
       "d4f01649de54f7e70c368da6571ac5ccda9ddf79                         0.0  \n",
       "bae8ac45f183613712be11aee11ec93b6e36e0d0                         0.0  \n",
       "9aa1369d290e7732b7ca8db743f27d10c0ace093                         0.0  \n",
       "9aa1369d290e7732b7ca8db743f27d10c0ace093                         0.0  \n",
       "...                                                              ...  \n",
       "4553a4f2a833f635e06b21120fd95dbd7dc3fe09                         0.0  \n",
       "05bb76f1e435db71754a65f9e8acec7dfdd4c65d                         0.0  \n",
       "4fb170389e1b482ed3c7fae2967caca7629c84a6                         0.0  \n",
       "ea00c9c71a474f84e3280537f04ede09ae70e44f                         0.0  \n",
       "fd5e6143d36ce5ffa6caff953de41436984b7fc3                         0.0  \n",
       "\n",
       "[781 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bd372a14",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.0\n",
      "8.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.0\n",
      "33.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "15.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in df[\"loop_input_dependent_level\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db0853",
   "metadata": {},
   "source": [
    "## 2. Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8adde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32ae7cf",
   "metadata": {},
   "source": [
    "# Garbage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93a08dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for node in ([obj, target] + (related_nodes or [])):\n",
      "    if isinstance(node, Project):\n",
      "        create_timelines.post(node.node_id)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fors = [] #this should be dataframe instead\n",
    "for function_node in func_nodes_of_files:\n",
    "    found_fors = loop_finder(function_node)\n",
    "    if len(found_fors) != 0:\n",
    "        fors.extend(found_fors)\n",
    "print(astor.to_source(for_nodes_of_files[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293386a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = []\n",
    "for file_dir in file_directories:\n",
    "    with open(file_dir, \"r\") as file:\n",
    "        source_code = file.read()\n",
    "    functions.extend(dependent_variable_finder(source_code))\n",
    "print(len(functions))\n",
    "print(astor.to_source(functions[10]))\n",
    "print(functions[10].func.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
